#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
xtf-runner - A utility for enumerating and running XTF tests.

Currently assumes the presence and availability of the `xl` toolstack.
"""

import os
import sys

from optparse import OptionParser
from subprocess import Popen, PIPE

from xtf import default_categories, non_default_categories, all_categories
from xtf import pv_environments, hvm_environments, all_environments
from xtf.exceptions import RunnerError
from xtf.logger import Logger
from xtf.suite import get_all_test_info, gather_all_test_info
from xtf.test import TestResult

# Return the exit code for different states.  Avoid using 1 and 2 because
# python interpreter uses them -- see document for sys.exit.
def exit_code(state):
    """ Convert a test result to an xtf-runner exit code. """
    return { TestResult.SUCCESS: 0,
             TestResult.SKIP:    3,
             TestResult.ERROR:   4,
             TestResult.FAILURE: 5,
             TestResult.CRASH:   6,
    }[state]

def parse_test_instance_string(arg):
    """Parse a test instance string.

    Has the form: '[[test-]$ENV-]$NAME[~$VARIATION]'

    Optional 'test-' prefix
    Optional $ENV environment part
    Mandatory $NAME
    Optional ~$VARIATION suffix

    Verifies:
      - $NAME is valid
      - if $ENV, it is valid for $NAME
      - if $VARIATION, it is valid for $NAME

    Returns: tuple($ENV or None, $NAME, $VARIATION or None)
    """

    all_tests = get_all_test_info()

    variation = None
    if '~' in arg:
        arg, variation = arg.split('~', 1)

    parts = arg.split('-', 2)
    parts_len = len(parts)

    # If arg =~ test-$ENV-$NAME
    if parts_len == 3 and parts[0] == "test" and parts[1] in all_environments:
        _, env, name = parts

    # If arg =~ $ENV-$NAME
    elif parts_len > 0 and parts[0] in all_environments:
        env, name = parts[0], "-".join(parts[1:])

    # If arg =~ $NAME
    elif arg in all_tests:
        env, name = None, arg

    # Otherwise, give up
    else:
        raise RunnerError("Unrecognised test '%s'" % (arg, ))

    # At this point, 'env' has always been checked for plausibility.  'name'
    # might not be

    if name not in all_tests:
        raise RunnerError("Unrecognised test name '%s' for '%s'"
                          % (name, arg))

    info = all_tests[name]

    if env and env not in info.envs:
        raise RunnerError("Test '%s' has no environment '%s'"
                          % (name, env))

    # If a variation has been given, check it is valid
    if variation is not None:
        if not info.variations:
            raise RunnerError("Test '%s' has no variations" % (name, ))
        elif not variation in info.variations:
            raise RunnerError("No variation '%s' for test '%s'"
                              % (variation, name))

    return env, name, variation

def tests_from_selection(cats, envs, tests):
    """Given a selection of possible categories, environment and tests, return
    all tests within the provided parameters.

    Multiple entries for each individual parameter are combined or-wise.
    e.g. cats=['special', 'functional'] chooses all tests which are either
    special or functional.  envs=['hvm64', 'pv64'] chooses all tests which are
    either pv64 or hvm64.

    Multiple parameter are combined and-wise, taking the intersection rather
    than the union.  e.g. cats=['functional'], envs=['pv64'] gets the tests
    which are both part of the functional category and the pv64 environment.

    By default, not all categories are available.  Selecting envs=['pv64']
    alone does not include the non-default categories, as this is most likely
    not what the author intended.  Any reference to non-default categories in
    cats[] or tests[] turns them all back on, so non-default categories are
    available when explicitly referenced.
    """

    all_tests = get_all_test_info()
    all_test_info = all_tests.values()
    res = []

    if cats:
        # If a selection of categories have been requested, start with all test
        # instances in any of the requested categories.
        for info in all_test_info:
            if info.cat in cats:
                res.extend(info.all_instances())

    if envs:
        # If a selection of environments have been requested, reduce the
        # category selection to requested environments, or pick all suitable
        # tests matching the environments request.
        if res:
            res = [ x for x in res if x.env in envs ]
        else:
            # Work out whether to include non-default categories or not.
            categories = default_categories
            if non_default_categories & set(cats):
                categories = all_categories

            elif tests:
                sel_test_names = set(x.name           for x in tests)
                sel_test_cats  = set(all_tests[x].cat for x in sel_test_names)

                if non_default_categories & sel_test_cats:
                    categories = all_categories

            for info in all_test_info:
                if info.cat in categories:
                    res.extend(info.all_instances(env_filter = envs))

    if tests:
        # If a selection of tests has been requested, reduce the results so
        # far to the requested tests (this is meaningful in the case that
        # tests[] has been specified without a specific environment), or just
        # take the tests verbatim.
        if res:
            res = [ x for x in res if x in tests ]
        else:
            res = tests

    # Sort the results
    res = sorted(res, key = lambda test: test.variation) # by variation third
    res = sorted(res, key = lambda test: test.env)       # by environment second
    res = sorted(res, key = lambda test: test.name)      # by name first
    return res


def interpret_selection(opts):
    """Interpret the argument list as a collection of categories, environments,
    pseduo-environments and partial and complete test names.

    Returns a list of all test instances within the selection.
    """

    args = set(opts.args)

    # First, filter into large buckets
    cats   = all_categories   & args
    envs   = all_environments & args
    others = args - cats - envs

    # Add all categories if --all or --non-default is passed
    if opts.all:
        cats |= default_categories
    if opts.non_default:
        cats |= non_default_categories

    # Allow "pv" and "hvm" as a combination of environments
    if "pv" in others:
        envs |= pv_environments
        others -= set(("pv", ))

    if "hvm" in others:
        envs |= hvm_environments
        others -= set(("hvm", ))

    # No input? No selection.
    if not cats and not envs and not others:
        return []

    all_tests = get_all_test_info()
    tests = []

    # Second, sanity check others as full or partial test names
    for arg in others:
        env, name, vary = parse_test_instance_string(arg)

        instances = all_tests[name].all_instances(
            env_filter = env and [env] or None,
            vary_filter = vary and [vary] or None,
        )

        if not instances:
            raise RunnerError("No appropriate instances for '%s' (env %s)"
                              % (arg, env))

        tests.extend(instances)

    selection = tests_from_selection(cats, envs, set(tests))

    # If the caller passed --host, filter out the unsupported environments
    if selection and opts.host:

        host_envs = []

        cmd = Popen(['xl', 'info'], stdout = PIPE)
        stdout, _ = cmd.communicate()

        for line in stdout.splitlines():
            if not line.startswith("xen_caps"):
                continue

            caps = line.split()[2:]

            if "xen-3.0-x86_64" in caps:
                host_envs.append("pv64")
            if "xen-3.0-x86_32p" in caps:
                host_envs.append("pv32pae")
            for cap in caps:
                if cap.startswith("hvm"):
                    host_envs.extend(hvm_environments)
                    break

            break

        selection = tests_from_selection(cats = set(),
                                         envs = set(host_envs),
                                         tests = selection)

    return selection


def list_tests(opts):
    """ List tests """

    if opts.environments:
        # The caller only wants the environment list
        for env in sorted(all_environments):
            print env
        return

    if not opts.selection:
        raise RunnerError("No tests selected")

    for sel in opts.selection:
        print sel

def run_tests(opts):
    """ Run tests """

    tests = opts.selection
    if not tests:
        raise RunnerError("No tests to run")

    rc = TestResult()
    results = []

    for test in tests:
        res = TestResult()
        test.set_up(opts, res)
        if res == TestResult.SUCCESS:
            test.run(res)
        test.clean_up(res)

        if res > rc:
            rc = res

        results.append(res)

    print "Combined test results:"

    for test, res in zip(tests, results):
        print "%-40s %s" % (test, res)

    return exit_code(rc)


def main():
    """ Main entrypoint """

    # Change stdout to be line-buffered.
    sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 1)

    # Normalise $CWD to the directory this script is in
    os.chdir(os.path.dirname(os.path.abspath(sys.argv[0])))

    # Avoid wrapping the epilog text
    OptionParser.format_epilog = lambda self, formatter: self.epilog

    parser = OptionParser(
        usage = "%prog [--list] <SELECTION> [options]",
        description = "Xen Test Framework enumeration and running tool",
        )

    # Python 2.4 doesn't support epilog.  Avoid the error when calling the
    # constructor by monkeypatching it into the object instead.  It will
    # simply be omitted from the --help text on older versions of Python.
    parser.epilog = (
        "\n"
        "Overview:\n"
        "  Running with --list will print the entire selection\n"
        "  to the console.  Running without --list will execute\n"
        "  all tests in the selection, printing a summary of their\n"
        "  results at the end.\n"
        "\n"
        "  To determine how runner should get output from Xen, use\n"
        '  --results-mode option. The default value is "console", \n'
        "  which means using xenconsole program to extract output.\n"
        '  The other supported value is "logfile", which\n'
        "  means to get output from log file.\n"
        "\n"
        '  The "logfile" mode requires users to configure\n'
        "  xenconsoled to log guest console output. This mode\n"
        "  is useful for Xen version < 4.8. Also see --logfile-dir\n"
        "  and --logfile-pattern options.\n"
        "\n"
        "Selections:\n"
        "  A selection is zero or more of any of the following\n"
        "  parameters: Categories, Environments and Tests.\n"
        "  Multiple instances of the same type of parameter are\n"
        "  unioned while the end result in intersected across\n"
        "  types.  e.g.\n"
        "\n"
        "    'functional xsa'\n"
        "       All tests in the functional and xsa categories\n"
        "\n"
        "    'functional xsa hvm32'\n"
        "       All tests in the functional and xsa categories\n"
        "       which are implemented for the hvm32 environment\n"
        "\n"
        "    'invlpg example'\n"
        "       The invlpg and example tests in all implemented\n"
        "       environments\n"
        "\n"
        "    'invlpg example pv'\n"
        "       The pv environments of the invlpg and example tests\n"
        "\n"
        "    'pv32pae-pv-iopl'\n"
        "       The pv32pae environment of the pv-iopl test only\n"
        "\n"
        "  Additionally, --host may be passed to restrict the\n"
        "  selection to tests applicable to the current host.\n"
        "  --all may be passed to choose all default categories\n"
        "  without needing to explicitly name them.  --non-default\n"
        "  is available to obtain the non-default categories.\n"
        "\n"
        "  The special parameter --environments may be passed to\n"
        "  get the full list of environments.  This option does not\n"
        "  make sense combined with a selection.\n"
        "\n"
        "Examples:\n"
        "  Listing all tests implemented for hvm32 environment:\n"
        "    ./xtf-runner --list hvm32\n"
        "\n"
        "  Listing all functional tests appropriate for this host:\n"
        "    ./xtf-runner --list functional --host\n"
        "\n"
        "  Running all the pv-iopl tests:\n"
        "    ./xtf-runner pv-iopl\n"
        "      <console ouput>\n"
        "    Combined test results:\n"
        "    test-pv64-pv-iopl                        SUCCESS\n"
        "    test-pv32pae-pv-iopl                     SUCCESS\n"
        "\n"
        "  Exit code for this script:\n"
        "    0:    everything is ok\n"
        "    1,2:  reserved for python interpreter\n"
        "    3:    test(s) are skipped\n"
        "    4:    test(s) report error\n"
        "    5:    test(s) report failure\n"
        "    6:    test(s) crashed\n"
        "\n"
    )

    parser.add_option("-l", "--list", action = "store_true",
                      dest = "list_tests",
                      help = "List tests in the selection",
                      )
    parser.add_option("-a", "--all", action = "store_true",
                      dest = "all",
                      help = "Select all default categories",
                      )
    parser.add_option("--non-default", action = "store_true",
                      dest = "non_default",
                      help = "Select all non default categories",
                      )
    parser.add_option("--environments", action = "store_true",
                      dest = "environments",
                      help = "List all the known environments",
                      )
    parser.add_option("--host", action = "store_true",
                      dest = "host", help = "Restrict selection to applicable"
                      " tests for the current host",
                      )
    parser.add_option("-m", "--results-mode", action = "store",
                      dest = "results_mode", default = "console",
                      type = "choice", choices = ("console", "logfile"),
                      help = "Control how xtf-runner gets its test results")
    parser.add_option("--logfile-dir", action = "store",
                      dest = "logfile_dir", default = "/var/log/xen/console/",
                      type = "string",
                      help = ('Specify the directory to look for console logs, '
                              'defaults to "/var/log/xen/console/"'),
                      )
    parser.add_option("--logfile-pattern", action = "store",
                      dest = "logfile_pattern", default = "guest-%s.log",
                      type = "string",
                      help = ('Specify the log file name pattern, '
                              'defaults to "guest-%s.log"'),
                      )
    parser.add_option("-q", "--quiet", action = "store_true",
                      dest = "quiet",
                      help = "Print only test results, without console output",
                      )

    opts, args = parser.parse_args()
    opts.args = args

    Logger().initialize(opts)

    gather_all_test_info()

    opts.selection = interpret_selection(opts)

    if opts.list_tests:
        return list_tests(opts)

    return run_tests(opts)


if __name__ == "__main__":
    try:
        sys.exit(main())
    except RunnerError, e:
        print >>sys.stderr, "Error:", e
        sys.exit(1)
    except KeyboardInterrupt:
        sys.exit(1)
